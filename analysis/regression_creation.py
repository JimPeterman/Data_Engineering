from sqlalchemy import create_engineimport pandas as pdimport numpy as npimport picklefrom sklearn.linear_model import LinearRegression# from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCVfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import mean_absolute_error, mean_squared_error# import xgboost as xg# from sklearn.preprocessing import StandardScalerimport matplotlib.pyplot as pltengine = create_engine("sqlite:///../../data_NO_github/friend.db")df = pd.read_sql("SELECT \                        Age, Sex, Country, Height, Weight, BMI,\                        CVDstatus, ExMode, MaxRER, VO2_rel\                     FROM data", engine)"""Build 2 regression models (one that includes country as a feature and onethat does not).Regression features include: sex, mode, BMI (or ht+wt), age,and country (for one of the models).Prediction will be VO2max.This only predicts for HEALTHY individuals (so no CVD)."""# Filtering extraneous values.df = df.query("CVDstatus == 0")df = df.query("Sex == 'Male' | Sex == 'Female'")df = df.query("ExMode == 'TM' | ExMode == 'CY'")df = df.query("VO2_rel > 5 & VO2_rel < 95")df = df.query("BMI > 15 & BMI < 60")df = df.query("Height > 48 & Height < 84")df = df.query("Weight > 38 & Weight < 500")df = df.query("Age >= 18 & Age < 90")# Filtering to final dataset.# Drop countries that don't have >100 tests.df = df.groupby("Country").filter(lambda x: len(x) > 100)# Drop Norway since there are data-use restrictions for that data.df = df.query("Country != 'NOR'")# Also require a "true" maximal test (RER >= 1.10).# Doing this filtering last means some have <100 tests but that's ok.df = df.query("MaxRER >= 1.10")# Drop rows with missing data for the features of interest.df = df.dropna(subset=["Age", "Sex", "Height", "Weight", "BMI", "CVDstatus",                                       "ExMode", "VO2_rel", "Country"])# Creating numeric for categorical. df["Sex_num"] = df.Sex.apply(lambda x: 1 if x == "Male" else 0)df["ExMode_num"] = df.ExMode.apply(lambda x: 1 if x == "TM" else 0)############ Model creation (OLS model WITH COUNTRY).# Create the test/train groups (80/20 split).# Ht and Wt seems to work just a little better than BMI.X = df[["Age", "Sex_num", "Height", "Weight", "ExMode_num", "Country"]]# Convert countries to binary.X = pd.get_dummies(X, drop_first=False)y = df["VO2_rel"]X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,                                                    random_state=13)# Build the model.lm_OLS = LinearRegression()# Fit the model.lm_OLS.fit(X_train, y_train)# Create predictions.X_train_pred = lm_OLS.predict(X_train)X_test_pred = lm_OLS.predict(X_test)with open('../data/reg_model_country.pickle', 'wb') as to_write:    pickle.dump(lm_OLS, to_write)# Save a list of the countries included to use for the streamlit app.lst_countries = list(df.Country.unique())# Sort the countries to match the output of the regression.lst_countries.sort()with open('../data/reg_model_country_lst.pickle', 'wb') as to_write:    pickle.dump(lst_countries, to_write)# Create a dictionary of model metrics.dct_model_metrics = {    "Train": dict(),    "Test": dict()}# dct_model_metrics["Train"]["R2"] = f"{lm_OLS.score(X_train, y_train):.2f}"dct_model_metrics["Test"]["R2"] = f"{lm_OLS.score(X_test, y_test):.2f}"dct_model_metrics["Test"]["RMSE"] = \    f"{(mean_squared_error(y_test, X_test_pred, squared=False)):.2f}"dct_model_metrics["Test"]["MAE"] = \    f"{(mean_absolute_error(y_test, X_test_pred)):.2f}"with open('../data/reg_model_country_metrics.pickle', 'wb') as to_write:    pickle.dump(dct_model_metrics, to_write)# Create a figure of the model performance.test_df = pd.concat([X_test, y_test], axis=1)test_df['predict'] = lm_OLS.predict(X_test)test_df['resid'] = test_df["VO2_rel"] - test_df["predict"]test_df['resid'] = test_df["VO2_rel"] - test_df["predict"]fig, axs = plt.subplots(figsize=(6,6))axs.scatter(data=test_df, x='VO2_rel',y='predict', alpha=0.2)# To add line of best fit.# line_fit = np.polyfit(test_df["VO2_rel"],test_df["predict"], 1)# axs[2].plot(test_df["VO2_rel"], line_fit[0]*test_df["VO2_rel"]+line_fit[1], color="k")p1 = max(max(test_df["VO2_rel"]), max(test_df["predict"]))p2 = min(min(test_df["VO2_rel"]), min(test_df["predict"]))axs.plot([p1, p2], [p1, p2], 'r--', linewidth=2.0)axs.legend(["Line of Identity"])axs.set_title("Model Fit on Test Data", fontweight="bold", fontsize=16)axs.set_xlabel("Actual VO2max Values (ml/kg/min)", weight="bold")axs.set_ylabel("Predicted VO2max Values (ml/kg/min)", weight="bold")with open('../data/reg_model_country_graph.pickle', 'wb') as to_write:    pickle.dump(fig, to_write)    # Create a Bland-Altman plot of model performance."""Bones of graph are from this Stack Overflow post:https://stackoverflow.com/questions/16399279/bland-altman-plot-in-pythonI added in text to the output to enhance interpretations."""predicted     = np.asarray(test_df["predict"])actual     = np.asarray(test_df["VO2_rel"])mean      = np.mean([predicted, actual], axis=0)diff      = predicted - actual                   # Difference between data1 and data2md        = np.mean(diff)                   # Mean of the differencesd        = np.std(diff, axis=0)            # Standard deviation of the differencefig, ax = plt.subplots(figsize=(6,6))ax.scatter(mean, diff, alpha=0.1)ax.axhline(md,           color='red', linestyle='--', linewidth=2.0)ax.text(55, md+2, "Bias")ax.text(55, md-3, f"{md:.1f}")ax.axhline(md + 1.96*sd, color='gray', linestyle='--')ax.text(55, (md + 1.96*sd)+2, "+1.96SD")ax.text(55, (md + 1.96*sd)-3, f"{md + 1.96*sd:.1f}")ax.axhline(md - 1.96*sd, color='gray', linestyle='--')ax.text(55, (md - 1.96*sd)+2, "-1.96SD")ax.text(55, (md - 1.96*sd)-3, f"{md - 1.96*sd:.1f}")ax.set_xlabel("Average Measure (ml/kg/min)", weight="bold")ax.set_ylabel("Predicted - Actual VO2max (ml/kg/min)", weight="bold")ax.set_title('Bland-Altman Plot', weight="bold", fontsize=16)with open('../data/reg_model_country_ba.pickle', 'wb') as to_write:    pickle.dump(fig, to_write)############ Model creation (Global OLS model - NO country).# Create train/test dataset, again 80/20 split.X = df[["Age", "Sex_num", "Height", "Weight", "ExMode_num"]]y = df["VO2_rel"]X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,                                                    random_state=13)# Build the model.lm_OLS_global = LinearRegression()# Fit the model.lm_OLS_global.fit(X_train, y_train)# Create predictions.X_train_pred = lm_OLS_global.predict(X_train)X_test_pred = lm_OLS_global.predict(X_test)with open('../data/reg_model_global.pickle', 'wb') as to_write:    pickle.dump(lm_OLS_global, to_write)# Create a dictionary of model metrics.dct_model_metrics_glb = {    "Train": dict(),    "Test": dict()}# dct_model_metrics["Train"]["R2"] = f"{lm_OLS_global.score(X_train, y_train):.2f}"dct_model_metrics_glb["Test"]["R2"] = f"{lm_OLS_global.score(X_test, y_test):.2f}"dct_model_metrics_glb["Test"]["RMSE"] = \    f"{(mean_squared_error(y_test, X_test_pred, squared=False)):.2f}"dct_model_metrics_glb["Test"]["MAE"] = \    f"{(mean_absolute_error(y_test, X_test_pred)):.2f}"with open('../data/reg_model_global_metrics.pickle', 'wb') as to_write:    pickle.dump(dct_model_metrics_glb, to_write)# Create a figure of the model performance.test_df = pd.concat([X_test, y_test], axis=1)test_df['predict'] = lm_OLS_global.predict(X_test)test_df['resid'] = test_df["VO2_rel"] - test_df["predict"]test_df['resid'] = test_df["VO2_rel"] - test_df["predict"]fig, axs = plt.subplots(figsize=(6,6))axs.scatter(data=test_df, x='VO2_rel',y='predict', alpha=0.2)# To add line of best fit.# line_fit = np.polyfit(test_df["VO2_rel"],test_df["predict"], 1)# axs[2].plot(test_df["VO2_rel"], line_fit[0]*test_df["VO2_rel"]+line_fit[1], color="k")p1 = max(max(test_df["VO2_rel"]), max(test_df["predict"]))p2 = min(min(test_df["VO2_rel"]), min(test_df["predict"]))axs.plot([p1, p2], [p1, p2], 'r--', linewidth=2.0)axs.legend(["Line of Identity"])axs.set_title("Model Fit on Test Data", fontweight="bold", fontsize=16)axs.set_xlabel("Actual VO2max Values (ml/kg/min)", weight="bold")axs.set_ylabel("Predicted VO2max Values (ml/kg/min)", weight="bold")with open('../data/reg_model_global_graph.pickle', 'wb') as to_write:    pickle.dump(fig, to_write)# Create a Bland-Altman plot of model performance."""Bones of graph are from this Stack Overflow post:https://stackoverflow.com/questions/16399279/bland-altman-plot-in-pythonI added in text to the output to enhance interpretations."""predicted     = np.asarray(test_df["predict"])actual     = np.asarray(test_df["VO2_rel"])mean      = np.mean([predicted, actual], axis=0)diff      = predicted - actual                   # Difference between data1 and data2md        = np.mean(diff)                   # Mean of the differencesd        = np.std(diff, axis=0)            # Standard deviation of the differencefig, ax = plt.subplots(figsize=(6,6))ax.scatter(mean, diff, alpha=0.1)ax.axhline(md,           color='red', linestyle='--', linewidth=2.0)ax.text(55, md+2, "Bias")ax.text(55, md-3, f"{md:.1f}")ax.axhline(md + 1.96*sd, color='gray', linestyle='--')ax.text(55, (md + 1.96*sd)+2, "+1.96SD")ax.text(55, (md + 1.96*sd)-3, f"{md + 1.96*sd:.1f}")ax.axhline(md - 1.96*sd, color='gray', linestyle='--')ax.text(55, (md - 1.96*sd)+2, "-1.96SD")ax.text(55, (md - 1.96*sd)-3, f"{md - 1.96*sd:.1f}")ax.set_xlabel("Average Measure (ml/kg/min)", weight="bold")ax.set_ylabel("Predicted - Actual VO2max (ml/kg/min)", weight="bold")ax.set_title('Bland-Altman Plot', weight="bold", size=16)with open('../data/reg_model_global_ba.pickle', 'wb') as to_write:    pickle.dump(fig, to_write)