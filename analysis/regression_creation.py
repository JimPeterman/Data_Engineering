from sqlalchemy import create_engineimport pandas as pdimport numpy as npimport picklefrom sklearn.linear_model import LinearRegressionfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import mean_absolute_error, mean_squared_errorimport matplotlib.pyplot as pltengine = create_engine("sqlite:///../../data_NO_github/friend.db")df = pd.read_sql("SELECT \                        Age, Sex, Country, Height, Weight, BMI,\                        CVDstatus, ExMode, MaxRER, VO2_rel\                     FROM data", engine)"""Build 2 regression models (one that includes country as a feature and onethat does not).Regression features include: sex, mode, BMI (or ht+wt), age,and country (for one of the models).Prediction will be VO2max.This only predicts for HEALTHY individuals (so no CVD)."""# Filtering extraneous values.df = df.query("CVDstatus == 0")df = df.query("Sex == 'Male' | Sex == 'Female'")df = df.query("ExMode == 'TM' | ExMode == 'CY'")df = df.query("VO2_rel > 5 & VO2_rel < 95")df = df.query("BMI > 15 & BMI < 60")df = df.query("Height > 48 & Height < 84")df = df.query("Weight > 38 & Weight < 500")df = df.query("Age >= 18 & Age < 90")# Filtering to final dataset.# Drop countries that don't have >100 tests.df = df.groupby("Country").filter(lambda x: len(x) > 100)# Drop Norway since there are data-use restrictions for that data.df = df.query("Country != 'NOR'")# Also require a "true" maximal test (RER >= 1.10).# Doing this filtering last means some have <100 tests but that's ok.df = df.query("MaxRER >= 1.10")# Drop rows with missing data for the features of interest.df = df.dropna(subset=["Age", "Sex", "Height", "Weight", "BMI", "CVDstatus",                                       "ExMode", "VO2_rel", "Country"])# Creating numeric for categorical. df["Sex_num"] = df.Sex.apply(lambda x: 1 if x == "Male" else 0)df["ExMode_num"] = df.ExMode.apply(lambda x: 1 if x == "TM" else 0)############ Model creation (OLS model WITH COUNTRY).# Create the test/train groups (80/20 split).# Ht and Wt seems to work just a little better than BMI.X = df[["Age", "Sex_num", "Height", "Weight", "ExMode_num", "Country"]]# Convert countries to binary.X = pd.get_dummies(X, drop_first=False)y = df["VO2_rel"]X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,                                                    random_state=13)# Build the model.lm_OLS = LinearRegression()# Fit the model.lm_OLS.fit(X_train, y_train)# Create predictions.X_train_pred = lm_OLS.predict(X_train)X_test_pred = lm_OLS.predict(X_test)with open('../data/reg_model_country.pickle', 'wb') as to_write:    pickle.dump(lm_OLS, to_write)# Save a list of the countries included to use for the streamlit app.lst_countries = list(df.Country.unique())# Sort the countries to match the output of the regression.lst_countries.sort()# Saving as txt file maybe better with lists compared to picklewith open("../data/reg_model_country_lst.txt", "w") as output:    output.write("\n".join(lst_countries))# with open('../data/reg_model_country_lst.pickle', 'wb') as to_write:#     pickle.dump(lst_countries, to_write)# Create a dictionary of model metrics.dct_model_metrics = {    "Train": dict(),    "Test": dict()}# dct_model_metrics["Train"]["R2"] = f"{lm_OLS.score(X_train, y_train):.2f}"dct_model_metrics["Test"]["R2"] = f"{lm_OLS.score(X_test, y_test):.2f}"dct_model_metrics["Test"]["RMSE"] = \    f"{(mean_squared_error(y_test, X_test_pred, squared=False)):.2f}"dct_model_metrics["Test"]["MAE"] = \    f"{(mean_absolute_error(y_test, X_test_pred)):.2f}"with open('../data/reg_model_country_metrics.pickle', 'wb') as to_write:    pickle.dump(dct_model_metrics, to_write)# Create a figure of the model performance.# First, create a function to return the figure# (it gets used below too for the global model).def model_fit_graph(predicted, actual):    fig, ax = plt.subplots(figsize=(6,6))    ax.scatter(x=actual, y=predicted, alpha=0.1)    # To add line of best fit.    # line_fit = np.polyfit(test_df["VO2_rel"],test_df["predict"], 1)    # axs[2].plot(test_df["VO2_rel"], line_fit[0]*test_df["VO2_rel"]+line_fit[1], color="k")    p1 = max(max(actual), max(predicted))    p2 = min(min(actual), min(predicted))    ax.plot([p1, p2], [p1, p2], 'r--', linewidth=2.0)    ax.legend(["Line of Identity"])    ax.set_title("Model Fit", fontweight="bold", fontsize=16)    ax.set_xlabel("Actual VO2max Values (ml/kg/min)", weight="bold")    ax.set_ylabel("Predicted VO2max Values (ml/kg/min)", weight="bold");    return fig,axtest_df = pd.concat([X_test, y_test], axis=1)test_df['predict'] = lm_OLS.predict(X_test)fig_reg, ax = model_fit_graph(test_df['predict'], test_df['VO2_rel'])with open('../data/reg_model_country_graph.pickle', 'wb') as to_write:    pickle.dump(fig_reg, to_write)    # Create a function to return Bland-Altman plot of model performance.def bland_altman_plot(predicted, actual):    """    Bones of graph are from this Stack Overflow post:    https://stackoverflow.com/questions/16399279/bland-altman-plot-in-python    I added in text to the output to enhance interpretations.    """    predicted     = np.asarray(predicted)    actual     = np.asarray(actual)    mean      = np.mean([predicted, actual], axis=0)    diff      = predicted - actual    md        = np.mean(diff)    sd        = np.std(diff, axis=0)    fig, ax = plt.subplots(figsize=(6,6))        ax.scatter(mean, diff, alpha=0.1)    ax.axhline(md, color='red', linestyle='--', linewidth=2.0)    ax.text(55, md+2, "Bias")    ax.text(55, md-3, f"{md:.1f}")    ax.axhline(md + 1.96*sd, color='gray', linestyle='--')    ax.text(55, (md + 1.96*sd)+2, "+1.96SD")    ax.text(55, (md + 1.96*sd)-3, f"{md + 1.96*sd:.1f}")    ax.axhline(md - 1.96*sd, color='gray', linestyle='--')    ax.text(55, (md - 1.96*sd)+2, "-1.96SD")    ax.text(55, (md - 1.96*sd)-3, f"{md - 1.96*sd:.1f}")        ax.set_xlabel("Average Measure (ml/kg/min)", weight="bold")    ax.set_ylabel("Predicted - Actual VO2max (ml/kg/min)", weight="bold")    ax.set_title('Bland-Altman Plot', fontsize=16, weight="bold")        return fig,axfig_ba, ax = bland_altman_plot(test_df["predict"],test_df["VO2_rel"])with open('../data/reg_model_country_ba.pickle', 'wb') as to_write:    pickle.dump(fig_ba, to_write)############ Model creation (Global OLS model - NO country).# Create train/test dataset, again 80/20 split.X = df[["Age", "Sex_num", "Height", "Weight", "ExMode_num"]]y = df["VO2_rel"]X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,                                                    random_state=13)# Build the model.lm_OLS_global = LinearRegression()# Fit the model.lm_OLS_global.fit(X_train, y_train)# Create predictions.X_train_pred = lm_OLS_global.predict(X_train)X_test_pred = lm_OLS_global.predict(X_test)with open('../data/reg_model_global.pickle', 'wb') as to_write:    pickle.dump(lm_OLS_global, to_write)# Create a dictionary of model metrics.dct_model_metrics_glb = {    "Train": dict(),    "Test": dict()}# dct_model_metrics["Train"]["R2"] = f"{lm_OLS_global.score(X_train, y_train):.2f}"dct_model_metrics_glb["Test"]["R2"] = f"{lm_OLS_global.score(X_test, y_test):.2f}"dct_model_metrics_glb["Test"]["RMSE"] = \    f"{(mean_squared_error(y_test, X_test_pred, squared=False)):.2f}"dct_model_metrics_glb["Test"]["MAE"] = \    f"{(mean_absolute_error(y_test, X_test_pred)):.2f}"with open('../data/reg_model_global_metrics.pickle', 'wb') as to_write:    pickle.dump(dct_model_metrics_glb, to_write)# Create a figure of the model performance.test_df = pd.concat([X_test, y_test], axis=1)test_df['predict'] = lm_OLS_global.predict(X_test)fig_reg, ax = model_fit_graph(test_df["predict"],test_df["VO2_rel"])with open('../data/reg_model_global_graph.pickle', 'wb') as to_write:    pickle.dump(fig_reg, to_write)# Bland-Altman plot.fig_ba, ax = bland_altman_plot(test_df["predict"],test_df["VO2_rel"])with open('../data/reg_model_global_ba.pickle', 'wb') as to_write:    pickle.dump(fig_ba, to_write)