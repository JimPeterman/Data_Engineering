from sqlalchemy import create_engineimport pandas as pd# import numpy as npimport picklefrom sklearn.linear_model import LinearRegression# from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCVfrom sklearn.model_selection import train_test_split# from sklearn.metrics import mean_absolute_error, mean_squared_error# import xgboost as xg# from sklearn.preprocessing import StandardScalerengine = create_engine("sqlite:///../../data_NO_github/friend.db")df = pd.read_sql("SELECT \                        Age, Sex, Country, Height, Weight, BMI,\                        CVDstatus, ExMode, MaxRER, VO2_rel\                     FROM data", engine)"""Build 2 regression models (one that includes country as a feature and onethat does not).Regression features include: sex, mode, BMI (or ht+wt), age,and country (for one of the models).Prediction will be VO2max.This only predicts for HEALTHY individuals (so no CVD)."""# Filtering extraneous values.df = df.query("CVDstatus == 0")df = df.query("Sex == 'Male' | Sex == 'Female'")df = df.query("ExMode == 'TM' | ExMode == 'CY'")df = df.query("VO2_rel > 5 & VO2_rel < 95")df = df.query("BMI > 15 & BMI < 60")df = df.query("Height > 48 & Height < 84")df = df.query("Weight > 38 & Weight < 500")df = df.query("Age >= 18 & Age < 90")# Filtering to final dataset.# Drop countries that don't have >100 tests.df = df.groupby("Country").filter(lambda x: len(x) > 100)# Drop Norway since there are data-use restrictions for that data.df = df.query("Country != 'NOR'")# Also require a "true" maximal test (RER >= 1.10).# Doing this filtering last means some have <100 tests but that's ok.df = df.query("MaxRER >= 1.10")# Drop rows with missing data for the features of interest.df = df.dropna(subset=["Age", "Sex", "Height", "Weight", "BMI", "CVDstatus",                                       "ExMode", "VO2_rel", "Country"])# Creating numeric for categorical. df["Sex_num"] = df.Sex.apply(lambda x: 1 if x == "Male" else 0)df["ExMode_num"] = df.ExMode.apply(lambda x: 1 if x == "TM" else 0)############ Model creation (OLS model WITH COUNTRY).# Create the test/train groups (80/20 split).# Ht and Wt seems to work just a little better than BMI.X = df[["Age", "Sex_num", "Height", "Weight", "ExMode_num", "Country"]]# Convert countries to binary.X = pd.get_dummies(X, drop_first=False)y = df["VO2_rel"]X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,                                                    random_state=13)# Build the model.lm_OLS = LinearRegression()# Fit the model.lm_OLS.fit(X_train, y_train)# Create predictions.X_train_pred = lm_OLS.predict(X_train)X_test_pred = lm_OLS.predict(X_test)with open('../data/reg_model_country.pickle', 'wb') as to_write:    pickle.dump(lm_OLS, to_write)# Save a list of the countries included to use for the streamlit app.lst_countries = list(df.Country.unique())# Sort the countries to match the output of the regression.lst_countries.sort()with open('../data/reg_model_country_lst.pickle', 'wb') as to_write:    pickle.dump(lst_countries, to_write)############ Model creation (Global OLS model - NO country).# Create train/test dataset, again 80/20 split.X = df[["Age", "Sex_num", "Height", "Weight", "ExMode_num"]]y = df["VO2_rel"]X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,                                                    random_state=13)# Build the model.lm_OLS_global = LinearRegression()# Fit the model.lm_OLS_global.fit(X_train, y_train)# Create predictions.X_train_pred = lm_OLS_global.predict(X_train)X_test_pred = lm_OLS_global.predict(X_test)with open('../data/reg_model_global.pickle', 'wb') as to_write:    pickle.dump(lm_OLS_global, to_write)